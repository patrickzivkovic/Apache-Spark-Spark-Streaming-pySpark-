{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import time\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas\n",
    "from textblob import TextBlob\n",
    "try:\n",
    "    import subprocess\n",
    "except:\n",
    "    %pip install subprocess\n",
    "    import subprocess\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('C:\\opt\\spark')\n",
    "# import necessary packages\n",
    "from pyspark import SparkContext\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.functions import desc\n",
    "sc = SparkContext()\n",
    "# we initiate the StreamingContext with 10 second batch interval. #next we initiate our sqlcontext\n",
    "ssc = StreamingContext(sc, 10)\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "\n",
    "# initiate streaming text from a TCP (socket) source:\n",
    "socket_stream = ssc.socketTextStream(\"127.0.0.1\", 5555)\n",
    "# lines of tweets with socket_stream window of size 60, or 60 #seconds windows of time\n",
    "lines = socket_stream.window(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "fields = (\"hashtag\", \"count\" )\n",
    "Tweet = namedtuple( 'Tweet', fields )\n",
    "\n",
    "fields2 = (\"text\", \"count\")\n",
    "Sentiment = namedtuple('Sentiment', fields2)\n",
    "\n",
    "# here we apply different operations on the tweets and save them to #a temporary sql table\n",
    "( lines.flatMap( lambda text: text.split( \"\\n\" ) ) #Splits to a list containing of the single tweets \n",
    "  .map( lambda word: ( word, 1) ) \n",
    "  .map( lambda rec: Sentiment( rec[0], rec[1] ) )\n",
    " # Sorts Them in a dataframe\n",
    "  .foreachRDD( lambda rdd: rdd.toDF().sort( desc(\"count\") )\n",
    "  .limit(50).registerTempTable(\"sentiment\") ) )\n",
    "    #  hier: alle texte müssen raus und schleife braucht viel zu lange...\n",
    "\n",
    "# here we apply different operations on the tweets and save them to #a temporary sql table\n",
    "( lines.flatMap( lambda text: text.split( \" \" ) ) #Splits to a list\n",
    "  # Checks for    hashtag calls  \n",
    "  .filter( lambda word: word.lower().startswith(\"#\") ) \n",
    "  .map( lambda word: ( word.lower(), 1 ) ) # Lower cases the word\n",
    "  .reduceByKey( lambda a, b: a + b ) \n",
    " # Stores in a Tweet Object\n",
    "  .map( lambda rec: Tweet( rec[0], rec[1] ) )\n",
    " # Sorts Them in a dataframe\n",
    "  .foreachRDD( lambda rdd: rdd.toDF().sort( desc(\"count\") )\n",
    " # Registers only top 10 hashtags to a table.\n",
    "  .limit(5).registerTempTable(\"tweets\") ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter searchword: ps5\n",
      "Search for: ps5\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    search = input(\"Enter searchword: \")\n",
    "    if(search != \"\"):\n",
    "        print(\"Search for: \" + search)\n",
    "        break\n",
    "    print(\"You have to use a searchword!\")\n",
    "\n",
    "search = search.split(\",\")\n",
    "\n",
    "#overwrite file\n",
    "f = open(\"var.py\", \"w\")\n",
    "f.write(\"search = %s\" % search)\n",
    "f.close()\n",
    "\n",
    "file = subprocess.Popen(\"job.sh\", shell = True)\n",
    "\n",
    "ssc.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Wait 60 seconds stream to start properly...\")\n",
    "time.sleep(60)\n",
    "print(\"...successfull\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot():\n",
    "    try:\n",
    "        error = 0\n",
    "        %matplotlib inline\n",
    "        while True:\n",
    "            print(\"Gather Data for graph...\")\n",
    "            time.sleep(5)\n",
    "            # top hashtags:\n",
    "            top_10_tags = sqlContext.sql( 'Select hashtag, count from tweets' )\n",
    "            top_10_df = top_10_tags.toPandas()\n",
    "            print(\"successful\")\n",
    "            print(\"plotting\")\n",
    "            #display.clear_output(wait=True)\n",
    "            plt.figure( figsize = ( 10, 8 ) )\n",
    "            sns.barplot( x=\"count\", y=\"hashtag\", data=top_10_df)\n",
    "            plt.show()\n",
    "            sentiment()\n",
    "    except:\n",
    "        print(\"Data was not ready for printing....waiting....\")\n",
    "        time.sleep(20)\n",
    "        error += 1\n",
    "        if(error >= 5):\n",
    "            print(\"Error on Streaming\")\n",
    "            ssc.stop()\n",
    "            exit()\n",
    "        plot()\n",
    "        \n",
    "def sentiment():\n",
    "    %matplotlib inline\n",
    "    error = 0\n",
    "    try:\n",
    "        print(\"Gater data for Sentiment Analysis...\")\n",
    "        #sentiment analysis:\n",
    "        top_10_senti = sqlContext.sql( 'Select text from sentiment' )\n",
    "        top_10_s = top_10_senti.toPandas()\n",
    "        print(\"successful\")\n",
    "        #print(top_10_s)\n",
    "        # Schleife über alle texte, die in top_10_s gespeichert sind, und davon jeweils die sentiment analysis\n",
    "        n = 51\n",
    "        positiveList = [] #empty list for storing positive tweets\n",
    "        negativeList = [] #empty list for storing negative tweets\n",
    "        countPosNeg = np.array([0, 0]) #array for counting positive and negative tweets --> 1 is positive, 0 is negative\n",
    "        countNames = np.array([\"negative\", \"positive\"]) #names for plotting\n",
    "        s = 0\n",
    "        i = 1\n",
    "        print(\"analyse text for sentiment...\")\n",
    "        while i <= n:\n",
    "            opinion = TextBlob(top_10_s[\"text\"][i])\n",
    "            if(opinion.sentiment[0] == 0.0 and opinion.sentiment[1] == 0.0): #text is not suitable for sentiment\n",
    "                i += 1\n",
    "                s += 1\n",
    "            else:\n",
    "                if(s <= 5):\n",
    "                    print(\"For the text: \", top_10_s[\"text\"][i])\n",
    "                    print(\"The text polarity is: %.2f\" %opinion.sentiment[0])\n",
    "                    print(\"The text subjectivity is: %.2f\" %opinion.sentiment[1])\n",
    "                    print(\"*****************************************************\")\n",
    "                if(opinion.sentiment[0] > 0):\n",
    "                    countPosNeg[1] += 1 #add 1 to positive count because sentiment was positive\n",
    "                    positiveList.append(opinion.sentiment[0])\n",
    "                else:\n",
    "                    countPosNeg[0] += 1 #add 1 to negatvie count because seintiment was negative\n",
    "                    negativeList.append(opinion.sentiment[0])\n",
    "                i += 1\n",
    "                s += 1\n",
    "        plt.figure( figsize = ( 10, 8 ))\n",
    "        sns.barplot( x=countNames, y=countPosNeg)\n",
    "        plt.show()\n",
    "        \n",
    "        plt.figure( figsize = ( 10, 8 ))\n",
    "        sns.boxplot( y=countNames, x=[positiveList, negativeList])\n",
    "        plt.show()\n",
    "        if(input(\"continue?(y/n): \") == \"y\"):\n",
    "            sentiment()\n",
    "        else:\n",
    "            ssc.stop()\n",
    "            exit()\n",
    "    except:\n",
    "        print(\"Data was not ready for sentiment...waiting...\")\n",
    "        time.sleep(20)\n",
    "        if(error >= 5):\n",
    "            print(\"Error on sentiment, getting not enough data!\")\n",
    "            ssc.stop()\n",
    "            exit()\n",
    "        error += 1\n",
    "        sentiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
